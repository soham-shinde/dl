{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a47554-8f30-497b-9762-c95e55b39527",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215de23-29d7-42a9-8585-96560adcfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "#VGG16 is a convolutional neural network (CNN) architecture\n",
    "# It is a very deep network with 16 layers, which makes it capable of learning very complex patterns in images.\n",
    "#used for- img classi, obj dete,img segmentation\n",
    "#often used as a starting point for transfer learning. \n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#ImageDataGenerator is a tool that simplifies the process of using transfer learning for image classification tasks. It allows you to automatically generate augmented data, which involves modifying existing images to create variations that the model can learn from. This helps the model become more robust and generalize better to new data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561828c-874c-4951-ba39-55cdc38bbe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#he Caltech-101 dataset is a collection of 101 categories of objects, with approximately 800 images per category.\n",
    "dataset_datagen=ImageDataGenerator(rescale=1.0/255,)# The rescale parameter is set to 1.0/255, which will normalize the pixel values of the images in the dataset to be between 0 and 1.\n",
    "\n",
    "#batch_size = 2000\n",
    "dataset_generator = dataset_datagen.flow_from_directory(  #generate batches of data from the Caltech-101 dataset\n",
    "    \"./caltech-101-img\", #path to ds\n",
    "    target_size=(64, 64), \n",
    "    batch_size=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b6181-0d75-4951-bed1-bfa04d741e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into training and testing sets\n",
    "x_train,y_train=dataset_generator[0]\n",
    "x_test,y_test=dataset_generator[1]\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4dccc-edbd-4251-83ec-5d2aca125e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggPath = \"./datasets/Object Detection(Ass6)/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "#The VGG16 weights file contains the weights that were learned when the VGG16 model was trained on the ImageNet dataset.\n",
    "base_model = VGG16(False, vggPath, input_shape=(64, 64, 3))\n",
    "#The include_top parameter is set to False, which means that the top layer of the VGG16 model, which is a fully connected layer that is used for image classification, will not be included in the new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c77b6b-9d9f-4e40-97db-694af81568a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "   layer.trainable = False\n",
    "#sets the trainable attribute of the current layer to False. This means that the weights of the layer will not be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab470bd-a05a-40c5-a228-3f163aa106f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "# Explanation: This line adds a Flatten layer to the output of the base_model. The Flatten layer is used to transform the 3D tensor output from the convolutional base (which is usually the output of the last convolutional layer) into a 1D tensor. This flattening step is necessary when transitioning from convolutional layers to densely connected layers.\n",
    "# Example: Suppose the output shape of base_model is (7, 7, 512). This means you have a 3D tensor with dimensions 7x7x512. Applying the Flatten layer converts this 3D tensor into a 1D tensor by unraveling the values along the dimensions. In this case, the resulting 1D tensor would have a size of 7 * 7 * 512 = 25088.\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(102, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# Compile the model\n",
    "model.compile(\"adam\", 'categorical_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062ef53-f7c2-4b0b-a666-8ad48c5d3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42898659-f5bf-436d-a2ee-cecce42f722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "##\n",
    "base_model = VGG16(weights=weights_path, include_top=False, input_shape=(64, 64, 3)) #creates new VGG16 model \n",
    "\n",
    "# freeze all layers first\n",
    "for layer in base_model.layers:\n",
    "   layer.trainable = False\n",
    "#i.e. weights of these layers will not be updated during training\n",
    "\n",
    "\n",
    "#-----\n",
    "# unfreeze last 4 layers of base model\n",
    "for layer in base_model.layers[len(base_model.layers) - 2:]:\n",
    "   layer.trainable = True\n",
    "#i.e. weights of these layers will be updates\n",
    "\n",
    "\n",
    "# fine-tuning hyper parameters\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "#-----\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "predictions = Dense(102, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(learning_rate=0.001), 'categorical_crossentropy', ['accuracy'])\n",
    "\n",
    "# training fine tuned model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476cb5e-e403-4c67-89cd-e24fee80cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = model.predict(x_test)\n",
    "predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df31015-02c3-4857-94b5-1b617b2efeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83fd77c-af8c-4053-91f4-31d17fe2675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(dataset_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b9cab-2284-4c27-8a44-2c0192c61700",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=101\n",
    "\n",
    "plt.imshow(x_test[n])\n",
    "print(\"Preditcted: \",labels[np.argmax(predicted_value[n])])\n",
    "print(\"Actual: \", labels[np.argmax(y_test[n])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f6cbec-8e12-4d21-abd6-4ec7eba0e0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a395046-6e6e-4c1c-8af5-22c7278bba37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec50abb-6c72-419f-94e1-72661b014b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3392b-b770-402d-acd7-c44c2b58f916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd5b5f-2380-49af-bc82-1d40af1a11b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1fbc37-a325-4903-ade8-64c831aace11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6be417-d724-4cd5-a6fc-a424f96fbb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0512ef-6049-4c8c-977d-14f1eed2a87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc60b61-697f-463e-879f-33f1cf76274b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85002a-4adb-47fc-b447-98fc93991347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cdd5e9-2d5a-4835-b029-bfb0eeadb21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967aadcd-d960-43a2-8b86-e1b92a1be738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
